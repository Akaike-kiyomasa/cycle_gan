{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Ey4b68emk5F8yxD3MgY5BnKuzSEN933Y",
      "authorship_tag": "ABX9TyPCBMrJFnv9bdzt4ENgtmOj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akaike-kiyomasa/cycle_gan/blob/main/CycleGAN_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKoGBWBbti8d"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing hiper-parameters"
      ],
      "metadata": {
        "id": "OZQL_zQhxd0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--n_epoch\", type=int, default=200)\n",
        "parser.add_argument(\"--batch_size\", type=int, default=1)\n",
        "parser.add_argument(\"--lr\", type=float, default=2e-4)\n",
        "parser.add_argument(\"--decay_start\", type=int, default=100)\n",
        "parser.add_argument(\"--weight_identity\", type=float, default=5.0)\n",
        "parser.add_argument(\"--weight_cycle\", type=float, default=10.0)\n",
        "parser.add_argument(\"--image_size\", type=int, default=256)\n",
        "parser.add_argument(\"--beta1\", type=float, default=0.5)\n",
        "opt = parser.parse_args(args=[])\n",
        "print(opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYNzT25EuYfj",
        "outputId": "19005e07-b5a5-44e8-e534-3d4e1e695f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(n_epoch=200, batch_size=1, lr=0.0002, decay_start=100, weight_identity=5.0, weight_cycle=10.0, image_size=256, beta1=0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "urlTsvCsxWQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Datasets"
      ],
      "metadata": {
        "id": "JiRbnT14xiX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "  def __init__(self, transform=None):\n",
        "    super().__init__()\n",
        "    self.files_A = glob.glob(\"./drive/MyDrive/data/horse2zebra/trainA/*.jpg\")\n",
        "    self.files_B = glob.glob(\"./drive/MyDrive/data/horse2zebra/trainB/*.jpg\")\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    imgA = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\n",
        "    while True:\n",
        "      random_index = np.random.randint(0, len(self.files_B)-1)\n",
        "      imgB = self.transform(Image.open(self.files_B[random_index % len(self.files_B)]))\n",
        "      C, H, W = imgB.size()\n",
        "      if C == 3:\n",
        "        break\n",
        "    return {\"A\": imgA, \"B\":imgB}\n",
        "\n",
        "  def __len__(self):\n",
        "    return max(len(self.files_A), len(self.files_B))\n",
        "\n",
        "class DecayLR(object):\n",
        "  def __init__(self, n_epochs, offset, decay_start_epoch):\n",
        "    self.n_epochs = n_epochs\n",
        "    self.offset = offset\n",
        "    self.decay_start_epoch = decay_start_epoch\n",
        "\n",
        "  def step(self, epoch):\n",
        "    return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)"
      ],
      "metadata": {
        "id": "eJGnm6s_xkEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer(object):\n",
        "  def __init__(self, max_size=50):\n",
        "    self.max_size = max_size\n",
        "    self.data = []\n",
        "\n",
        "  def push_and_pop(self, data):\n",
        "    to_return = []\n",
        "    for element in data.data:\n",
        "      element = torch.unsqueeze(element, 0)\n",
        "      if len(self.data) < self.max_size:\n",
        "        self.data.append(element)\n",
        "        to_return.append(element)\n",
        "      else:\n",
        "        if np.random.rand() > 0.5:\n",
        "          i = np.random.randint(0, self.max_size -1)\n",
        "          to_return.append(self.data[i].clone())\n",
        "          self.data[i] = element\n",
        "        else:\n",
        "          to_return.append(element)\n",
        "    return torch.cat(to_return)"
      ],
      "metadata": {
        "id": "h8PuCIW2zJON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TYT2DCFG0MAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Design of Generator"
      ],
      "metadata": {
        "id": "ymlT_9lK0Qwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_channels):\n",
        "    super().__init__()\n",
        "    self.conv_layers = nn.Sequential(\n",
        "        nn.ReflectionPad2d(1),\n",
        "        nn.Conv2d(in_channels, in_channels, 3),\n",
        "        nn.InstanceNorm2d(in_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.ReflectionPad2d(1),\n",
        "        nn.Conv2d(in_channels, in_channels, 3),\n",
        "        nn.InstanceNorm2d(in_channels)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv_layers(x)\n",
        "    out += x\n",
        "    return out"
      ],
      "metadata": {
        "id": "HYc3-oa10TNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, res_block, in_channels=3):\n",
        "    super().__init__()\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.ReflectionPad2d(3),\n",
        "        nn.Conv2d(in_channels, 64, 7),\n",
        "        nn.InstanceNorm2d(64),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "        nn.InstanceNorm2d(128),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
        "        nn.InstanceNorm2d(256),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "    #\n",
        "    ### transformer\n",
        "    #\n",
        "    self.res_block = res_block(256)\n",
        "    self.transformer = nn.ModuleList([\n",
        "        res_block(256),\n",
        "        res_block(256),\n",
        "        res_block(256),\n",
        "        res_block(256),\n",
        "        res_block(256),\n",
        "        res_block(256),\n",
        "        res_block(256),\n",
        "        res_block(256),\n",
        "        res_block(256)\n",
        "    ])\n",
        "\n",
        "    #\n",
        "    ### Decoder\n",
        "    #\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
        "        nn.InstanceNorm2d(128),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
        "        nn.InstanceNorm2d(64),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        nn.ReflectionPad2d(3),\n",
        "        nn.Conv2d(64, 3, 7),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.encoder(x)\n",
        "    for func in self.transformer:\n",
        "      out = func(out)\n",
        "    out = self.decoder(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "ljCUsGaCwyBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0tiL_YXW0Tke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Design of discriminator"
      ],
      "metadata": {
        "id": "FqFKV5uf0W1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = self.conv_layer(3, 64, 4, 2, 1, False)\n",
        "    self.conv2 = self.conv_layer(64, 128, 4, 2, 1, False)\n",
        "    self.conv1 = self.conv_layer(128, 256, 4, 2, 1, False)\n",
        "    self.conv1 = self.conv_layer(256, 512, 4, 1, 1, False)\n",
        "    self.conv5 = nn.Conv2d(512, 1, 4, 1, padding=1)\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def conv_layer(in_channels, out_channels, kernel_size, stride, padding, has_norm=False):\n",
        "    layers =[nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)]\n",
        "    if has_norm:\n",
        "      layers.append(nn.InstanceNorm2d(out_channels))\n",
        "    layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "    net = nn.Sequential(*layers)\n",
        "    return net\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv1(x)\n",
        "    out = self.conv2(out)\n",
        "    out = self.conv3(out)\n",
        "    out = self.conv4(out)\n",
        "    out = self.conv5(out)\n",
        "    B, C, H, W = out.size()\n",
        "    out = F.avg_pool2d(out, (H,W))\n",
        "    out = out.view(B, -1)\n",
        "    return out"
      ],
      "metadata": {
        "id": "bYs_q6930aCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Srfmc127-qGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inisialize weights"
      ],
      "metadata": {
        "id": "cwvWXkGd-qd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find(\"Conv\") !=-1:\n",
        "    nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "  elif classname.find(\"BatchNorm\") !=-1:\n",
        "    nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "    nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "id": "NWMWKKde-5AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ijd71omL_FBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PreProcessing"
      ],
      "metadata": {
        "id": "OdYBd1fr_HbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(int(opt.image_size*1.12), Image.BICUBIC),\n",
        "    transforms.RandomCrop(opt.image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,),(0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "35WY7CU__JbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_9_3V4ZgARwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare dataset dataloader"
      ],
      "metadata": {
        "id": "GJqkTT1YAZM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ImageDataset(transform=transform)\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=opt.batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "aI3eMuM-Abv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "bKzD4IIBA3zC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QHoQmb-aCKB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instance"
      ],
      "metadata": {
        "id": "f5wmxZ6xvxBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netG_A2B = Generator(ResidualBlock).to(device)\n",
        "netG_B2A = Generator(ResidualBlock).to(device)\n",
        "netD_A = Discriminator().to(device)\n",
        "netD_B = Discriminator().to(device)"
      ],
      "metadata": {
        "id": "hEa757_Gv0Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netG_A2B.apply(weights_init)\n",
        "netG_B2A.apply(weights_init)\n",
        "netD_A.apply(weights_init)\n",
        "netD_B.apply(weights_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQRXJ7uLwFaH",
        "outputId": "5b865a0b-b9f6-4ae0-baa0-5e1f9f003123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  )\n",
              "  (conv5): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "89f8KAsEwdyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Function"
      ],
      "metadata": {
        "id": "D0vmDFizxPX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_loss = torch.nn.MSELoss().to(device)\n",
        "cycle_loss = torch.nn.L1Loss().to(device)\n",
        "identity_loss = torch.nn.L1Loss().to(device)"
      ],
      "metadata": {
        "id": "koekYkwixR0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fvGCFFWq2oEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_D_A = optim.Adam(netD_A.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "optimizer_D_B = optim.Adam(netD_A.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "optimizer_G = optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()), lr=opt.lr, betas=(opt.beta1,0.999))"
      ],
      "metadata": {
        "id": "lnre7_UOx6qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_lambda = DecayLR(opt.n_epoch, 0, opt.decay_start).step\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lr_lambda)\n",
        "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=lr_lambda)\n",
        "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=lr_lambda)"
      ],
      "metadata": {
        "id": "y2Uwh-HZykBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OWft9HwczaZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Directory for Outputs"
      ],
      "metadata": {
        "id": "u43lQ83L0NpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "model_name = \"CycleGAN\"\n",
        "f_path_result = \"./drive/MyDrive/result/{}\".format(model_name)\n",
        "f_path_params = \"./drive/MyDrive/params/{}\".format(model_name)\n",
        "\n",
        "os.makedirs(f_path_result, exist_ok=True)\n",
        "os.makedirs(f_path_params, exist_ok=True)"
      ],
      "metadata": {
        "id": "4yLYfl320RKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_params(epoch, dir_path, model_list, model_name_list):\n",
        "  for model, model_name in zip(model_list, model_name_list):\n",
        "    file_path = dir_path + \"/{model}_{epoch}.pth\".format(model=model_name, epoch=epoch)\n",
        "    torch.save(model.state_dict(), file_path)"
      ],
      "metadata": {
        "id": "Y8ME3XPfLjYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s9X-gzkiMWTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "-hLL9eMQMYad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()\n",
        "\n",
        "for epoch in range(0, opt.n_epoch):\n",
        "  running_loss_D = 0.0\n",
        "  running_loss_G = 0.0\n",
        "  running_loss_G_GAN = 0.0\n",
        "  running_loss_G_cycle = 0.0\n",
        "  running_loss_G_identity = 0.0\n",
        "  for data in tqdm.tqdm(dataloader, position=0):\n",
        "    real_imag_A = data[\"A\"].to(device)\n",
        "    real_imag_B = data[\"B\"].to(device)\n",
        "    batch_size = real_imag_A.size()[0]\n",
        "    real_label = torch.ones([batch_size, 1]).to(device)\n",
        "    fake_label = torch.zeros([batch_size,1]).to(device)\n",
        "    #\n",
        "    # train Generator\n",
        "    #\n",
        "    optimizer_G.zero_grad()\n",
        "    #\n",
        "    # adversarial loss\n",
        "    #\n",
        "    fake_img_A = netG_B2A(real_imag_B)\n",
        "    fake_img_B = netG_A2B(real_imag_A)\n",
        "    output_A = netD_A(fake_img_A)\n",
        "    output_B = netD_B(fake_img_B)\n",
        "\n",
        "    loss_GAN_A2B = adversarial_loss(output_B, real_label)\n",
        "    loss_GAN_B2A = adversarial_loss(output_A, real_label)\n",
        "    #\n",
        "    # cycle loss\n",
        "    #\n",
        "    cycle_img_A = netG_B2A(fake_img_B)\n",
        "    cycle_img_B = netG_A2B(fake_img_A)\n",
        "\n",
        "    loss_cycle_ABA = cycle_loss(cycle_img_A, real_imag_A)\n",
        "    loss_cycle_BAB = cycle_loss(cycle_img_B, real_imag_B)\n",
        "    #\n",
        "    # identity loss\n",
        "    #\n",
        "    identity_img_A = netG_B2A(real_imag_A)\n",
        "    identity_img_B = netG_A2B(real_imag_B)\n",
        "    loss_identity_A = identity_loss(identity_img_A, real_imag_A)\n",
        "    loss_identity_B = identity_loss(identity_img_B, real_imag_B)\n",
        "    #\n",
        "    # Total loss\n",
        "    #\n",
        "    lossG = (loss_GAN_A2B + loss_GAN_B2A +\n",
        "             opt.weight_identity*(loss_identity_A + loss_identity_B) + opt.weight_cycle * (loss_cycle_ABA + loss_cycle_BAB))\n",
        "    lossG.backward()\n",
        "    optimizer_G.step()\n",
        "    #\n",
        "    # train Discriminator\n",
        "    #\n",
        "    optimizer_D_A.zero_grad()\n",
        "    optimizer_D_B.zero_grad()\n",
        "\n",
        "    real_output_A = netD_A(real_imag_A)\n",
        "    real_output_B = netD_B(real_imag_B)\n",
        "    loss_DA_real = adversarial_loss(real_output_A, real_label)\n",
        "    loss_DB_real = adversarial_loss(real_output_B, real_label)\n",
        "\n",
        "    fake_img_A = fake_A_buffer.push_and_pop(fake_img_A)\n",
        "    fake_img_B = fake_B_buffer.push_and_pop(fake_img_B)\n",
        "    fake_output_A = netD_A(fake_img_A.detach())\n",
        "    fake_output_B = netD_B(fake_img_B.detach())\n",
        "\n",
        "    loss_DA_fake = adversarial_loss(fake_output_A, fake_label)\n",
        "    loss_DB_fake = adversarial_loss(fake_output_B, fake_label)\n",
        "\n",
        "    loss_DA = (loss_DA_real + loss_DA_fake)*0.5\n",
        "    loss_DB = (loss_DB_real + loss_DB_fake)*0.5\n",
        "\n",
        "    loss_DA.backward()\n",
        "    loss_DB.backward()\n",
        "    optimizer_D_A.step()\n",
        "    optimizer_D_B.step()\n",
        "\n",
        "    #\n",
        "    # adding to running loss\n",
        "    #\n",
        "    running_loss_D += (loss_DA.item()+ loss_DB.ite()) / 2.0\n",
        "    running_loss_G += lossG.item()\n",
        "    running_loss_G_GAN += (loss_GAN_A2B.item()+loss_GAN_B2A.item()) /2.0\n",
        "    running_loss_G_cycle += (loss_cycle_ABA.item()+loss_cycle_BAB.item()) /2.0\n",
        "    running_loss_G_identity += (loss_identity_A.item()+ loss_identity_B.item())/2.0\n",
        "  lr_scheduler_G.step()\n",
        "  lr_scheduler_D_A.step()\n",
        "  lr_scheduler_D_B.step()\n",
        "  running_loss_D /= len(dataloader)\n",
        "  running_loss_G /= len(dataloader)\n",
        "  running_loss_G_GAN /= len(dataloader)\n",
        "  running_loss_G_cycle /= len(dataloader)\n",
        "  running_loss_G_identity /= len(dataloader)\n",
        "  loss_log = \"\"\"epoch: {}, Loss D: {}, Loss G GAN: {},\n",
        "   Loss G cycle: {}, Loss G identity: {}\"\"\".format(epoch, running_loss_D, running_loss_G, running_loss_G_GAN, running_loss_G_cycle, running_loss_G_identity)\n",
        "  print(loss_log)\n",
        "\n",
        "  fake_imgs = torch.cat([fake_img_A, fake_img_B])\n",
        "  grdi_imgs = vutils.make_grid(fake_imgs.detach())\n",
        "  grdi_imgs_arr = grdi_imgs.cpu().numpy()\n",
        "  plt.imshow(np.transpose(grdi_imgs_arr, (1, 2, 0)))\n",
        "  plt.show()\n",
        "  model_list = [netG_A2B, netG_B2A, netD_A, netD_B]\n",
        "  model_name_list = [\"netG_A2B\", \"netG_B2A\", \"netD_A\", \"netD_B\"]\n",
        "  save_params(epoch, f_path_params, model_list, model_name_list)"
      ],
      "metadata": {
        "id": "iMzs-mx6MbED",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "e0443323-b79c-4c68-b161-6fd335fe89b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1213 [00:09<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-3d3456d1b046>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mfake_img_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG_B2A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_imag_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfake_img_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG_A2B\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_imag_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0moutput_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_img_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0moutput_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD_B\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_img_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-70598cf62fa5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [512, 256, 4, 4], expected input[1, 3, 256, 256] to have 256 channels, but got 3 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cyBX6K-DIllQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}